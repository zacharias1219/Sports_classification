{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import imageDataGenerator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Richa\\OneDrive\\Documents\\Projects\\Deployments\\Sports_classification\\data\"\n",
    "output_model = r\"C:\\Users\\Richa\\OneDrive\\Documents\\Projects\\Deployments\\Sports_classification\\output_model\"\n",
    "output_lable_binarizer = r\"C:\\Users\\Richa\\OneDrive\\Documents\\Projects\\Deployments\\Sports_classification\\output_lable_binarizer\"\n",
    "epoch=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sports_Lable = set([\"boxing\",\"swimming\",\"table_tennis\"])\n",
    "print(\"images are being uploaded.....\")\n",
    "path_to_images = list(paths.list_images(data_path))\n",
    "data =[]\n",
    "lables =[]\n",
    "\n",
    "for image_path in path_to_images:\n",
    "    lable = image_path.split(os.path.sep)[-2]\n",
    "    if lable in Sports_Lable:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image,(224,224))\n",
    "        data.append(image)\n",
    "        lables.append(lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "lables = np.array(lables)\n",
    "lb = LabelBinarizer()\n",
    "lables = lb.fit_transform(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, lables, test_size=0.25, stratify=lables, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingAugmentation =  imageDataGenerator(\n",
    "                                rotation_range = 30,\n",
    "                                zoom_range = 0.15,\n",
    "                                width_shift_range = 0.2,\n",
    "                                height_shift_range = 0.2,\n",
    "                                shear_range = 0.15,\n",
    "                                horizontal_flip = True,\n",
    "                                fill_mode = \"nearest\"\n",
    "                                )\n",
    "valiadationAugmentation = imageDataGenerator()\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainingAugmentation.mean = mean\n",
    "valiadationAugmentation.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "head_model = base_model.output\n",
    "head_model = AveragePooling2D(pool_size=(7, 7))(head_model)\n",
    "head_model = Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(512, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(len(lb.classes_), activation=\"softmax\")(head_model)\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    trainingAugmentation.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    validation_data=valiadationAugmentation.flow(X_test, y_test),\n",
    "    validation_steps=len(X_test) // 32,\n",
    "    epochs=epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(output_model)\n",
    "lbinarizer = open(\"video_classification_binarizer.pickel\", \"wb\")\n",
    "lbinarizer.write(pickle.dumps(lb))\n",
    "lbinarizer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
